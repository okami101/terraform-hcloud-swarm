terraform {
  required_providers {
    hcloud = {
      source = "hetznercloud/hcloud"
    }
  }

  backend "kubernetes" {
    secret_suffix = "cloud"
  }
}

provider "hcloud" {
  # Here is the required hcloud API token with RW access in order to create all needed resources.
  token = "xxxxxx"
}

resource "hcloud_ssh_key" "default" {
  name       = "john"
  public_key = "ssh-ed25519 xxxxxx"
}

module "hcloud_swarm" {
  providers = {
    hcloud = hcloud
  }

  # Next all self-explanatory variables that you can customized. See https://registry.terraform.io/modules/okami101/swarm/hcloud/latest?tab=inputs for description.

  source = "okami101/swarm/hcloud"

  server_image    = "ubuntu-22.04"
  server_location = "nbg1"
  server_timezone = "Europe/Paris"
  server_locale   = "fr_FR.UTF-8"
  
  # Install nfs-common in order for any NFS server to attach to workers.
  server_packages = ["nfs-common"]

  # Use preferably something different than default 22.
  ssh_port = 2222

  # All hostname will use it as a prefix, aka <cluster_name>-worker-01, etc.
  cluster_name = "swarm"
  # The unix user for ssh login.
  cluster_user = "swarm"

  # The above hcloud ssh key names for adding them when creating nodes.
  my_ssh_key_names   = [hcloud_ssh_key.default.name]
  # Your required public ssh key for ssh access through all nodes.
  my_public_ssh_keys = [hcloud_ssh_key.default.public_key]
  # Put your fixed public ip here, heavily recommended for protecting ssh and kube server api port access on bastion server, default to any.
  my_ip_addresses = ["0.0.0.0/0", "::/0"]

  managers = {
    # Swarm managers configuration
    server_type = "cx21"
    location    = "nbg1"
    # Use an odd number
    count       = 1
    # When HA mode, associate managers to a dedicated load balancer
    # Optional attribute, remove it to use manager ips directly
    lb_type     = "lb11"
  }

  # Swarm worker pools configuration
  worker_nodepools = [
    {
      # Will define the final hostname, aka <cluster_name>-worker-01, etc.
      name              = "worker"
      server_type       = "cx21"
      location          = "nbg1"
      # You can use next optional attribute to define the range private IP index for the nodepool. It allows to move items in the list without breaking the IP range.
      private_ip_index  = 0
      # The number of nodes in this pool. The main parameter for autoscaling.
      count             = 2
      # Associate nodepool to a dedicated load balancer (optional)
      lb_type           = "lb11"
    },
    {
      # Here is an example of a nodepool with a different server type dedicated for storage.
      name              = "storage"
      server_type       = "cx31"
      private_ip_index  = 1
      count             = 1
    }
  ]
}

resource "hcloud_load_balancer_service" "http_service" {
  load_balancer_id = module.hcloud_swarm.lbs.worker.id
  protocol         = "tcp"
  listen_port      = 80
  destination_port = 80
}

output "ssh_config" {
  value = module.hcloud_swarm.ssh_config
}
